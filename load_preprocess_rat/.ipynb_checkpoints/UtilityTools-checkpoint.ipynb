{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isClock(sig,fs):\n",
    "    sigM=np.mean(sig)\n",
    "    sig2=sig-sigM\n",
    "    sig2=np.sign(sig2)#clock is a perfect binary signal now\n",
    "    if len(sig) > 5*60*fs: #5min\n",
    "        L=int(5*60*fs)\n",
    "    else:\n",
    "        L=len(sig)-1\n",
    "    if np.corrcoef(sig[:L],sig2[:L])[0,1] > 0.98:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def prm_reader(prmFile):\n",
    "    CWD=os.getcwd()\n",
    "    try:\n",
    "        os.chdir(os.path.dirname(prmFile))\n",
    "        prmName=os.path.basename(prmFile)\n",
    "        %run $prmName\n",
    "    finally:\n",
    "        os.chdir(CWD)\n",
    "    return globals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading entire excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadExcelFile:\n",
    "    def __init__(self,root,animal,fileName=None):\n",
    "        self.animal=animal\n",
    "        self.excelPath=''\n",
    "        if fileName is None:\n",
    "            path=os.path.join(root,animal,animal)+'*.xls*'\n",
    "            excelfiles=glob.glob(path)\n",
    "            assert len(excelfiles)!=0, \"No Excel files\"+path\n",
    "            assert len(excelfiles) ==1, \"Too many Excel files\"+str(excelfiles)\n",
    "            self.excelPath=excelfiles[0]\n",
    "        else:\n",
    "            self.excelPath=fileName\n",
    "            assert os.path.isfile(self.excelPath), \"Bad Excel file path\"\n",
    "        \n",
    "        self.read_excel_file()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \" \".join(['Excel file at:',self.excelPath])\n",
    "\n",
    "    \n",
    "    def read_excel_file(self):\n",
    "        with pd.ExcelFile(self.excelPath) as file:\n",
    "            sheets=file.sheet_names\n",
    "            self.excelData={sheet:pd.read_excel(file,sheet) for sheet in sheets}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find files based on extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_file(path, extension=['.raw.kwd']):\n",
    "    \"\"\"\n",
    "    This function finds all the file types specified by 'extension' (ex: *.dat) in the 'path' directory\n",
    "    and all its subdirectories and their sub-subdirectories etc., \n",
    "    and returns a list of all file paths\n",
    "    'extension' is a list of desired file extensions: ['.dat','.prm']\n",
    "    \"\"\"\n",
    "    if type(extension) is str:\n",
    "        extension=extension.split()   #turning extension into a list with a single element\n",
    "    return [os.path.join(walking[0],goodfile) for walking in list(os.walk(path)) \n",
    "         for goodfile in walking[2] for ext in extension if goodfile.endswith(ext)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class permtest_output:\n",
    "    def __init__(self,D0,shuffledD=None,p_val=None,band=None, pairwise_CI=None,sig_signal=None):\n",
    "        self.statistic=D0\n",
    "        self.shuffled_data=shuffledD\n",
    "        self.p_val=p_val\n",
    "        self.significant=sig_signal\n",
    "        self.boundary=band\n",
    "        self.pairwise_alpha=pairwise_CI\n",
    "        self.significant=sig_signal\n",
    "\n",
    "        \n",
    "def perm_statistic(x,y,Nx,Ny,sigma=0):\n",
    "    \n",
    "    if len(x) <2:\n",
    "        return (x/Nx)-(y/Ny)\n",
    "    \n",
    "    #the gaussian kernel\n",
    "    x_smooth=scipy.ndimage.filters.gaussian_filter1d(x, sigma=sigma, order=0, mode='constant', cval=0, truncate=4.0)\n",
    "    y_smooth=scipy.ndimage.filters.gaussian_filter1d(y, sigma=sigma, order=0, mode='constant', cval=0, truncate=4.0)\n",
    "    \n",
    "    return (x_smooth/Nx)-(y_smooth/Ny)\n",
    "    \n",
    "def permtest(x,y, iterN=1000,sigma=0.05):\n",
    "    \"\"\"\n",
    "    Permutation test as to whether x>y or not.\n",
    "    x,y:\n",
    "    represent the data. they could be eitherr one dimentional(several realizations)\n",
    "    or 2-D (several realizaions through out the time/space/... course)\n",
    "        EX: x.shape==(15,500) means 15 trials/samples over 500 time bins\n",
    "    \n",
    "    iterN:\n",
    "    number of iterations used to shuffle. max(iterN)=(len(x)+len(y))!/len(x)!len(y)!\n",
    "    \n",
    "    sigma:\n",
    "    the standard deviation of the gaussian kernel used for smoothing when there are multiple data points,\n",
    "    based on the Fujisawa 2008 paper, default value: 0.05\n",
    "    \"\"\"\n",
    "    \n",
    "    #input check\n",
    "    if x.ndim>2 or y.ndim>2:\n",
    "        raise ValueError('bad input dimentions')\n",
    "    elif x.ndim==1 or y.ndim==1:\n",
    "        x=np.reshape(x,(len(x),1))\n",
    "        y=np.reshape(y,(len(y),1))\n",
    "    \n",
    "    #computing the tset statistic\n",
    "    xTrial,yTrial=x.shape[0],y.shape[0]\n",
    "    \n",
    "    x_superimpos=np.nansum(x,axis=0)\n",
    "    y_superimpos=np.nansum(y,axis=0)\n",
    "    \n",
    "    D0=perm_statistic(x_superimpos,y_superimpos,x.shape[0],y.shape[0])\n",
    "    \n",
    "    # shuffling the data\n",
    "    Dshuffled=np.ones((iterN,len(x_superimpos)))*np.nan\n",
    "    for i in range(iterN):\n",
    "        tmpShuffle=np.concatenate((x,y),axis=0)\n",
    "        np.random.shuffle(tmpShuffle)  #works in-plcae\n",
    "        xNew,yNew=tmpShuffle[:xTrial,:],tmpShuffle[xTrial:,:]\n",
    "        \n",
    "        xNew_superimpos=np.nansum(xNew,axis=0)\n",
    "        yNew_superimpos=np.nansum(yNew,axis=0)\n",
    "        \n",
    "        Dshuffled[i,:]=perm_statistic(xNew_superimpos,yNew_superimpos,xNew.shape[0],yNew.shape[0],sigma)\n",
    "    \n",
    "    if len(D0)<2:  #single point comparison\n",
    "        p_val0=np.sum(Dshuffled>=D0,axis=0)/(iterN+1)\n",
    "        return permtest_output(D0=D0,p_val=p_val0,shuffledD=Dshuffled,sig_signal=bool(p_val0<=0.05))\n",
    "    \n",
    "    #global bands\n",
    "    alpha=100\n",
    "    CI=5  #global confidance interval\n",
    "    pairwise_high_band=np.percentile(a=Dshuffled,q=100-CI,axis=0)\n",
    "    \n",
    "    while alpha>=5:\n",
    "        high_band=np.percentile(a=Dshuffled,q=100-CI,axis=0)\n",
    "        breaks=np.sum([np.sum(Dshuffled[i,:]>high_band)>1 for i in range(iterN)])\n",
    "        alpha=(breaks/iterN)*100\n",
    "        CI=0.95*CI\n",
    "        print(\"Global Confidence interval at \",CI,'\\nComputing again...\\n')\n",
    "    \n",
    "    #finding significant bins\n",
    "    global_sig=D0>high_band\n",
    "    pairwise_sig=D0>pairwise_high_band\n",
    "    sigIndex=np.where(global_sig)[0]\n",
    "    \n",
    "    for i in sigIndex:\n",
    "        if i==0 or i==len(global_sig):\n",
    "            continue\n",
    "        global_sig[np.min((np.where(pairwise_sig[:i])[0][-1],i)):np.max((np.where(pairwise_sig[i:])[0][-1],i))]=True\n",
    "    \n",
    "    return permtest_output(D0=D0,shuffledD=Dshuffled,sig_signal=global_sig,p_val=CI,band=high_band)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample size control by random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sample_size_control:\n",
    "    def __init__(self,func,animalList,NbAnimal,n,**kwargs):\n",
    "        \"\"\"\n",
    "        func: function to be applied to the randomly chosen animals\n",
    "        NbAnimal: number of animals to be considered in each iteration of func\n",
    "        n: max number of iterations\n",
    "        kwargs: give any input necessary to run \"func\" comma-seperated, like normal function arguments\n",
    "        \"\"\"\n",
    "        if NbAnimal>len(animalList):\n",
    "            raise (\"NbAnimal must be smaller than animal list\")\n",
    "#         if n==0:\n",
    "#             tmp=scipy.special.comb(len(animalList), NbAnimal, exact=True, repetition=False)\n",
    "#             n=max([1000,tmp])\n",
    "        \n",
    "        self.iterN=n\n",
    "        self.animalList=animalList\n",
    "        self.func=func\n",
    "        self.subsetSize=NbAnimal\n",
    "        self.kwargs=kwargs\n",
    "        \n",
    "        self.animalRepeat=np.ones(len(self.animalList))\n",
    "\n",
    "        self.Results=self.run_function()\n",
    "        \n",
    "        \n",
    "    def random_animal_subset(self):\n",
    "        prob=np.sum(self.animalRepeat)*(1/self.animalRepeat)\n",
    "        prob=prob/np.sum(prob)\n",
    "        animalListSubset=np.random.choice(a=self.animalList,size=self.subsetSize,replace=False,p=prob)\n",
    "        self.animalRepeat+=[animal in animalListSubset for animal in self.animalList]\n",
    "\n",
    "        return animalListSubset\n",
    "            \n",
    "    def run_function(self):\n",
    "        #inputArgs=inspect.getargspec(self.func)[0]\n",
    "        i=0\n",
    "        result=[]\n",
    "        Args=self.kwargs\n",
    "\n",
    "        #calculating estimated time needed to process\n",
    "        t0=time.perf_counter()\n",
    "        Args.update({'animalList':self.random_animal_subset()})\n",
    "        result.append(self.func(**Args))\n",
    "        Args.update({'animalList':self.random_animal_subset()})\n",
    "        result.append(self.func(**Args))\n",
    "        i=2\n",
    "        t_elapsed=(time.perf_counter()-t0)/2\n",
    "        print(\"Estimated time to run sample size control<\"+str(t_elapsed*self.iterN)+'s')\n",
    "\n",
    "        while i<self.iterN:\n",
    "            Args.update({'animalList':self.random_animal_subset()})\n",
    "            result.append(self.func(**Args))\n",
    "            i+=1\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### session RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rmse(data,onlyGood=False,maxTreadmillLength=90,raw=False):\n",
    "    '''\n",
    "    Compute the rmse of the position between trial start and trial stop (treadmill stop)\n",
    "    plots and returns the RMSE matrix\n",
    "    '''\n",
    "    allTraj=get_positions_array_beginning(data,onlyGood=onlyGood,raw=raw)\n",
    "    NbTrial=allTraj.shape[0]\n",
    "    \n",
    "    if NbTrial<3:\n",
    "        title=\"Not enough trials\"\n",
    "        med=np.nan\n",
    "        return med\n",
    "\n",
    "    rmse=np.ones((NbTrial,NbTrial))*(-1)\n",
    "\n",
    "    for i in range(NbTrial):\n",
    "        rmse[i,i]=0\n",
    "        for j in range(i+1,NbTrial):\n",
    "            maxL=min([np.sum(np.logical_not(np.isnan(allTraj[i,:]))),np.sum(np.logical_not(np.isnan(allTraj[j,:])))])\n",
    "            rmse[i,j]=np.sqrt(np.sum((allTraj[i,:maxL]-allTraj[j,:maxL])**2)/maxL)\n",
    "    \n",
    "    RMSEmatrix=np.triu(rmse,k=0)+np.triu(rmse,k=0).T #symetrical\n",
    "    RMSEmatrix/=maxTreadmillLength\n",
    "    pp=plt.pcolor(RMSEmatrix,vmin=0,vmax=1,cmap=\"Reds\")\n",
    "    plt.colorbar(pp)\n",
    "    plt.xlim([0,RMSEmatrix.shape[0]])\n",
    "    plt.ylim([0,RMSEmatrix.shape[1]])\n",
    "    \n",
    "    #median of upper triangle of matrix\n",
    "    coef=RMSEmatrix[np.tril_indices(RMSEmatrix.shape[0],-1)]\n",
    "    #print(len(coef))\n",
    "    med=np.nanmedian(coef)\n",
    "    maxSecond=allTraj.shape[1]/float(data.cameraSamplingRate)\n",
    "    #title of the plot\n",
    "    title=\"\"\n",
    "    if onlyGood:\n",
    "        title=\"Good Trials\"\n",
    "    else:\n",
    "        title=\"All Trials\"\n",
    "\n",
    "    title+=', trajectory median  r= %.2f'%med     \n",
    "    plt.title(title)\n",
    "\n",
    "    \n",
    "    return med,RMSEmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_trajectory_PDF(data,TimeRes=.5,PosRes=5,onlyGood=False,**kargs):\n",
    "    \"\"\"\n",
    "    calculates and plots the joint PDF of trajectories.\n",
    "    time resolution in seconds\n",
    "    Position resolution in cm\n",
    "    \"\"\"\n",
    "    \n",
    "    #data=Data(root,session[:6],session,defaultParam,redoPreprocess=False)\n",
    "    allTraj=get_positions_array_beginning(data,onlyGood).T\n",
    "    trialDuration=scipy.stats.mode(data.maxTrialDuration)[0]\n",
    "\n",
    "    posSize =len(np.arange(data.treadmillRange[0],data.treadmillRange[1],PosRes))\n",
    "    timeSize=len(np.arange(0,trialDuration,TimeRes))\n",
    "    trajDis=np.zeros([timeSize,posSize])\n",
    "    \n",
    "    #replacing nans w/ the last position\n",
    "    allTraj=allTraj//PosRes\n",
    "\n",
    "    for t in range(allTraj.shape[0]-1):\n",
    "        timeIndex=int((t/data.cameraSamplingRate)//TimeRes)\n",
    "        trajDis[timeIndex,:]=[np.sum(allTraj[t,:]==x) for x in range(posSize)]\n",
    "\n",
    "    trajDis=scipy.ndimage.filters.gaussian_filter(trajDis, sigma=[1,1],\n",
    "                                                  order=0, mode='nearest', truncate=3)\n",
    "    #normalizing as a PDF\n",
    "    trajDis/=np.sum(trajDis)\n",
    "\n",
    "#     plt.figure();\n",
    "    plt.pcolor(trajDis.T, cmap=cm.hot,**kargs);\n",
    "    ax=plt.gca();\n",
    "    ax.set_xticks     (np.linspace(0,timeSize,5));\n",
    "    ax.set_xticklabels(np.linspace(0,trialDuration,5));\n",
    "    ax.set_yticks     (np.linspace(0,posSize,10));\n",
    "    ax.set_yticklabels(np.linspace(data.treadmillRange[0],data.treadmillRange[1],10));\n",
    "    \n",
    "    return trajDis\n",
    "\n",
    "def twoD_entropy(trajDist):\n",
    "    H=0\n",
    "    for i in range(trajDist.shape[0]):\n",
    "        for j in range(trajDist.shape[1]):\n",
    "            try:\n",
    "                H+=trajDist[i,j]*math.log(float(trajDist[i,j]),2)\n",
    "            except:\n",
    "                pass\n",
    "    H=-H\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read session files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(data,paramName,extension=\".behav_param\",exclude=None,valueType=str):\n",
    "    '''\n",
    "    Use to read from .behav_param or .entrancetimes\n",
    "    Look for lines containing \"paramName\" and not containing \"exclude\"\n",
    "    Split them by white spaces \n",
    "    example: \"treadmill speed:     30.00\" becomes [\"treadmill\",\"speed:\",\"30.00\"])\n",
    "    Return a list of their last element, in the specified valueType (in example: \"30.00\")\n",
    "    '''\n",
    "    behav=data.fullPath+extension\n",
    "    if not os.path.exists(behav):\n",
    "        print(\"No file %s\"%behav)\n",
    "        data.hasBehavior=False\n",
    "        return []\n",
    "    result=[]\n",
    "    trials=[0]\n",
    "    with open(behav,\"r\") as f:\n",
    "        for line in f:\n",
    "            if \"Trial #\" in line:\n",
    "                trials.append(int(float(line.split()[-1]))-1)\n",
    "            if paramName in line:\n",
    "                if (exclude is not None) and (exclude in line):\n",
    "                    continue\n",
    "                res=line.split()[-1]\n",
    "                #integer or float: replace comma by dots\n",
    "                if valueType in [int,float]:\n",
    "                    res=res.replace(\",\",\".\")                 \n",
    "                #integer: convert first to float (\"0.00\" -> 0.00 -> 0)\n",
    "                if valueType is int:\n",
    "                    res=int(float(res))\n",
    "                #boolean \"TRUE\" \"FALSE\"\n",
    "                elif valueType is bool:\n",
    "                    res=(res.lower()==\"true\")\n",
    "                else:\n",
    "                    res=valueType(res)\n",
    "                result.append( (trials[-1],res) )\n",
    "    out=[np.nan]*(trials[-1]+1)\n",
    "    for item in result:\n",
    "        out[item[0]]=item[1]\n",
    "    return np.asarray(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_rate(timePoints,minDis=0,maxDis=np.inf):\n",
    "    \"\"\"\n",
    "    timePoints: list of times of occuring of events (in sec)\n",
    "    minDis= minimum distance between events to be considered valid\n",
    "    \"\"\"\n",
    "    tDiff=np.diff(timePoints)\n",
    "    tDiff=tDiff[np.logical_and(tDiff>minDis,tDiff<maxDis)]\n",
    "    return 1/np.nanmean(tDiff)\n",
    "\n",
    "def compute_rate (x,winLen,overlap=0.5,zero=0,end=None):\n",
    "    \"\"\"\n",
    "    x: list like data with times of event, in sec\n",
    "    winLen: length of window in sec\n",
    "    overlap: normalized overlap: (0,1)\n",
    "    zero: begining of the time axis\n",
    "    end: maximum of time axis\n",
    "    window: window param of scipy.signal.get_window\n",
    "    \"\"\"\n",
    "    assert overlap<1 and overlap>0, \"bad overlap value\"\n",
    "    x=np.array(x)\n",
    "    if end is None:\n",
    "        end=x[-1]\n",
    "#     if window is None:\n",
    "#         window='boxcar'\n",
    "#     win=scipy.signal.get_window(window,winLen)\n",
    "    Range=np.arange(zero,end,(1-overlap)*winLen)\n",
    "    out=[]\n",
    "    for i,_ in enumerate(Range):\n",
    "        a=x[np.logical_and(x>=Range[i],x<Range[i]+winLen)]\n",
    "        out.append(len(a)/winLen)\n",
    "    return np.array(out),Range"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
