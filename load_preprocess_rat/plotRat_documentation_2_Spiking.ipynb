{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import collections  as mc\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "\n",
    "if \"__file__\" not in dir():\n",
    "    %run loadRat_documentation.ipynb\n",
    "    %run loadRawSpike_documentation.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "# INFO: all the default parameters for preprocessing\n",
    "defaultParam={\n",
    "    \"binSize\":0.25,\n",
    "    \"trialOffset\":20., #max end of trial, in seconds (position will be cutted)\n",
    "    \"sigmaSmoothPosition\":0.1,  #smooth the position\n",
    "    #\"sigmaSmoothPosition\":0.33 for pavel dataType\n",
    "    \"sigmaSmoothSpeed\":0.3, #smooth the speed\n",
    "    \"positionDiffRange\": [2.,5.], #min and max differences allowed between two consecutive positions\n",
    "                                  #min to correct start, max to correct jumps\n",
    "    \"pawFrequencyRange\":[2.,10.],\n",
    "    \"startAnalysisParams\":[10,0.2,0.5],\n",
    "    \"cameraToTreadmillDelay\":2., #seconds, usual time between camera start and treadmill start\n",
    "    \"nbJumpMax\" : 100., #if jumps>nbJumpMax, trial is badly tracked\n",
    "    \n",
    "    #parameter to detect end of trial (first position minima)\n",
    "    \"endTrial_backPos\":55,  # minima is after the animal went once to the back (after first time position>backPos)\n",
    "    \"endTrial_frontPos\":30, # minima's position is in front of treadmill (position[end]<frontPos)\n",
    "    \"endTrial_minTimeSec\":4, # minima is after minTimeSec seconds (time[end]>minTimeSec)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load the preprocess data (corrected and binned position, speed, median position, ...)\n",
    " DEFAULT: load pickle if they exist, or create them\n",
    "data=Data(root,animal,experiment,param=param)\n",
    "\n",
    " OPTION 1: do not save any new pickle file\n",
    "data=Data(root,animal,experiment,param,saveAsPickle=False)\n",
    "\n",
    " OPTION 2: redo the preprocessing with param, even if the pickle already exist\n",
    " (to be sure everything is preprocess with the same parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    root=\"/data\"\n",
    "    animal=\"Rat034\"\n",
    "    experiment=\"Rat034_2015_06_15_10_03\"\n",
    "    param={\n",
    "        \"goalTime\":7,\n",
    "        \"treadmillRange\":[0,90],\n",
    "        \"maxTrialDuration\":20,\n",
    "        \"interTrialDuration\":10,\n",
    "        \"endTrial_frontPos\":30,\n",
    "        \"endTrial_backPos\":55, \n",
    "        \"endTrial_minTimeSec\":4,\n",
    "        \"binSize\":0.25,\n",
    "    }  \n",
    "    data=Data(root,animal,experiment,param,redoPreprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display all attributes and their type  \n",
    "Every attributes can be access with `data.attributeName`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run only if inside this notebook (do not execute if \"%run this_notebook\")\n",
    "if \"__file__\" not in dir():\n",
    "    data.describe()\n",
    "    print(data.emptyAnalysisFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shank and their clusters, per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run only if inside this notebook (do not execute if \"%run this_notebook\")\n",
    "if \"__file__\" not in dir():\n",
    "    # add a list of (shank,clu) in a group \"testGroup\"\n",
    "    #data.add_cluster_group(\"testGroup\",[(1,2),(1,3),(2,4)])\n",
    "    if not data.hasSpike:\n",
    "        print(\"no spike data\")\n",
    "    else:\n",
    "        #display all groups for every shank\n",
    "        for shank in data.channelGroupList:\n",
    "            print(\"shank %s:\"%shank)\n",
    "            print(data.clusterGroup[shank])\n",
    "        print(data.channelGroupList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiking Activity : Needs Revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster(data,shank,cluster,minTime=-5,maxTime=20,firstTrial=15,ax=None,legend=False,alignEnd=False):\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "        \n",
    "    ax.set_ylim(firstTrial,data.nTrial)\n",
    "    ax.set_ylabel('trial number',fontsize=12)\n",
    "\n",
    "    if alignEnd:\n",
    "        ax.axvline(x=0,linestyle=\"--\",color=\"k\",label=\"Detected end (0)\")\n",
    "        ax.set_xlabel('time relative to detected end (s)',fontsize=12)\n",
    "        ax.set_title('Shank %s Cluster %s, aligned on end'%(shank,cluster),fontsize=15)\n",
    "    else:\n",
    "        ax.axvline(x=0,linestyle=\"--\",color=\"k\",label=\"Treadmill start (0)\")\n",
    "        ax.set_xlabel('time relative to treadmill start (s)',fontsize=12)\n",
    "        ax.set_title('Shank %s Cluster %s'%(shank,cluster),fontsize=15)\n",
    "\n",
    "    cluSpikeTime=data.spikeTime[shank][cluster]\n",
    "    lines=[]\n",
    "    for trial in data.trials:\n",
    "        zero=data.treadmillStartTime[trial]\n",
    "        if alignEnd:\n",
    "            end=data.timeEndTrial[trial]\n",
    "            if isNone(end):\n",
    "                continue\n",
    "            zero=zero+end\n",
    "        start=zero+minTime\n",
    "        stop=zero+maxTime\n",
    "        trialSpikeTime=cluSpikeTime[(cluSpikeTime>=start)&(cluSpikeTime<=stop)]\n",
    "        for spikeTime in trialSpikeTime:\n",
    "            alignTime=spikeTime-zero\n",
    "            lines.append([(alignTime,trial+1),(alignTime,trial+1.9)])        \n",
    "    lc= mc.LineCollection(lines,colors=\"blue\",label=\"spikes\")\n",
    "    ax.add_collection(lc)\n",
    "        \n",
    "    ax.set_xlim([minTime,maxTime])\n",
    "    \n",
    "    ax2=ax.twinx()\n",
    "    ax2.axis(\"off\")\n",
    "    \n",
    "    #Plot median position and entrance time\n",
    "    if alignEnd:\n",
    "        trials=[trial for trial in data.trials if not isNone(data.timeEndTrial[trial])]\n",
    "        entrance=[data.entranceTime[trial]-data.timeEndTrial[trial] for trial in trials]\n",
    "        trialAxis=[trial+1 for trial in trials]\n",
    "        ax2.plot(data.timeAlignEnd,data.medianPositionAlignEnd,'g-',linewidth=2,label=\"Median position\")\n",
    "        ax.plot(entrance,trialAxis,'rx',label=\"Entrance times\");\n",
    "    else:\n",
    "        entrance=[data.entranceTime[trial] for trial in data.trials]\n",
    "        trialAxis=np.arange(1,data.nTrial+1)+0.4\n",
    "        ax2.plot(data.timeBin,data.medianPosition,'g-',linewidth=2,label=\"Median position\");\n",
    "        ax.plot(entrance,data.realTrials,'rx',label=\"Entrance times\");\n",
    "            \n",
    "    if legend:\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1.1, 0.5));\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    print(data.clusterGroup)\n",
    "    SHANK=1\n",
    "    CLU=17\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(211)\n",
    "    plot_raster(data,SHANK,CLU,legend=True)\n",
    "    plt.subplot(212)\n",
    "    plot_raster(data,SHANK,CLU,legend=True,minTime=-10,maxTime=10,alignEnd=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raster and mean with firing rate\n",
    "\n",
    "`pcolormesh(x,y,res)`: x and y are coordinates of rectangles. Each rectangle is colored according to the value in res\n",
    "\n",
    "To display `res` as 3x3 cells, you need:\n",
    "\n",
    "      res        x        y\n",
    "               |0 1 2 3|  |0|\n",
    "    |0 1 2|               |1|\n",
    "    |4 0 0|               |2|\n",
    "    |5 3 1|               |3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_firing_rate(data,shank,cluster,binSize,minTime,maxTime):\n",
    "    timeBin=np.arange(minTime,maxTime+binSize-maxTime%binSize,binSize)\n",
    "    firingRate={}\n",
    "    spikeTime=data.spikeTime[shank][cluster]\n",
    "    for trial in data.trials:\n",
    "        zero=data.treadmillStartTime[trial]\n",
    "        start=zero+minTime\n",
    "        stop=zero+maxTime\n",
    "        trialSpikeTime=spikeTime[(spikeTime>=start)&(spikeTime<=stop)]\n",
    "        alignedTime=trialSpikeTime-zero\n",
    "        hist,bins=np.histogram(alignedTime,timeBin)\n",
    "        firingRate[trial]=hist/float(binSize)\n",
    "    center=(timeBin[:-1]+timeBin[1:])/2\n",
    "    return firingRate,center,timeBin\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "def plot_raster_firing_rate(data,shank,cluster,binSize=0.25,minTime=-5,maxTime=20,ax=None):\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "        \n",
    "    firingRate,center,timeBin=compute_firing_rate(data,shank,cluster,binSize,minTime,maxTime)\n",
    "    res=np.asarray(list(firingRate.values()))\n",
    "    \n",
    "    y= [t+0.5 for t in range(1,len(data.trials)+2)]\n",
    "    resColor=ax.pcolormesh(timeBin,y,res,cmap=\"Greys\")\n",
    "\n",
    "    box = ax.get_position()\n",
    "    axColor = plt.axes([box.x0*1.02 + box.width * 1.02, box.y0, 0.01, box.height])\n",
    "    plt.colorbar(resColor, cax=axColor, label=\"firing rate\")\n",
    "\n",
    "    ax2=ax.twinx()\n",
    "    ax2.plot(data.timeBin,data.medianPosition,'g-',linewidth=2,label=\"Median position\");\n",
    "    ax2.axis(\"off\")\n",
    "    \n",
    "    entrance=[data.entranceTime[trial-1] for trial in data.realTrials]\n",
    "    ax.plot(entrance,data.realTrials,\"rx\")\n",
    "    \n",
    "    ax.set_xlim([timeBin[0],timeBin[-1]])\n",
    "    ax.set_ylim([data.realTrials[0],data.realTrials[-1]])\n",
    "    ax.set_xlabel(\"Time relative to treadmill start\")\n",
    "    ax.set_ylabel(\"Trial Number\")\n",
    "    ax.set_title(\"Cluster %s, firing rate, binSize=%s s\"%(cluster,data.binSize))\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "def plot_mean_firing_rate(data,shank,cluster,binSize=0.25,minTime=-5,maxTime=20,sigma=1,ax=None):\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "    \n",
    "    firingRate,center,timeBin=compute_firing_rate(data,shank,cluster,binSize,minTime,maxTime)\n",
    "    spikeCount=np.mean(list(firingRate.values()),axis=0)\n",
    "    \n",
    "    import scipy.ndimage as scImage\n",
    "    smoothSpikeCount=scImage.filters.gaussian_filter1d(spikeCount, sigma) \n",
    "    \n",
    "    ax.plot(center,smoothSpikeCount);\n",
    "    ax.set_xlabel(\"Time relative to treadmill start\")\n",
    "    ax.set_ylabel(\"Mean firing rate\")\n",
    "    ax.set_title(\"Cluster %s, mean firing rate + gaussian (sigma=%s)\"%(cluster,sigma))  \n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    SHANK=1\n",
    "    CLU=17\n",
    "\n",
    "    plt.figure(figsize=(8,10))\n",
    "    plt.subplot(211)\n",
    "    plot_raster_firing_rate(data,SHANK,CLU,binSize=0.1)\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plot_mean_firing_rate(data,SHANK,CLU,binSize=0.1,sigma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raster trial by trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_raster_one_trial(data,shank,cluster,trial,minTime=0,maxTime=20,ax=None):\n",
    "    '''\n",
    "    Position for one trial + spike times for one cluster\n",
    "    Paw=True: plot paw position\n",
    "    A trial time range is [treadmillStart+minTime, treadmillStart+maxTime]\n",
    "    times are aligned on treadmillStart\n",
    "    '''\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "    if trial in data.trialNotTracked:\n",
    "        print(\"Trial not tracked\")\n",
    "        return\n",
    "\n",
    "    cluData=data.spikeTime[shank][cluster]\n",
    "\n",
    "    zero=data.treadmillStartTime[trial]\n",
    "    start=zero+minTime\n",
    "    stop=zero+maxTime\n",
    "    trialSpikeTime=cluData[(cluData>start)&(cluData<stop)]-zero\n",
    "   \n",
    "    ax2=ax.twinx()\n",
    "    ax2.axis(\"off\")\n",
    "    lines=[]\n",
    "    for spike in trialSpikeTime:\n",
    "        lines.append([(spike,0),(spike,1)])\n",
    "    lc= mc.LineCollection(lines,colors=\"blue\",label=\"spike\",linestyle=\"--\",linewidth=0.5)\n",
    "    ax2.add_collection(lc)\n",
    "    nbSpike=len(trialSpikeTime)\n",
    "\n",
    "    ax.plot(data.entranceTime[trial],5,'rx',zorder=10);\n",
    "    ax.plot(data.timeTreadmill[trial],data.position[trial],'g-',linewidth=3,zorder=9);\n",
    "\n",
    "    ax.set_ylim(data.treadmillRange)\n",
    "    ax.set_xlim([minTime,maxTime])\n",
    "    ax.set_title('Shank %s Cluster %s, trial %s (%s spikes)'%(shank,cluster,trial,nbSpike));\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "def plot_raster_trial_by_trial(data,shank,cluster,group=\"not specified\",minTime=0,maxTime=20,paw=False):\n",
    "    '''\n",
    "    -Raster for all trials with median position (firing rate if nbSpike>20000)\n",
    "    -One plot for every trial (plot_raster_one_trial: position + spike time)\n",
    "    Paw=True: plot paw position\n",
    "    A trial time range is [treadmillStart+minTime, treadmillStart+maxTime]\n",
    "    times are aligned on treadmillStart\n",
    "    '''\n",
    "    nbcol=3 #nbcol=2 will result in Value Error (plot too big) \n",
    "    nbLines=int(np.ceil(data.nTrial*1.0/nbcol))\n",
    "    gs=gridspec.GridSpec(nbLines+1,nbcol,hspace=0.5)\n",
    "\n",
    "    plt.figure(figsize=(15,nbLines*(15.0/nbcol)))\n",
    "    ax=plt.subplot(gs[0,0:2])\n",
    "    if len(data.spikeTime[shank][cluster])<20000:\n",
    "        plot_raster(data,shank,cluster)\n",
    "    else:\n",
    "        plot_raster_firing_rate(data,shank,cluster)\n",
    "    ax.text(1.2,0.5,\"Shank %s, Cluster %s \\n(group %s)\"%(shank,cluster,group),transform=ax.transAxes,fontsize=15)\n",
    "\n",
    "    gs=gridspec.GridSpec(nbLines+1,nbcol,hspace=0.2)\n",
    "\n",
    "    for trial in data.trials[:-1]:\n",
    "        axT = plt.subplot(gs[1+trial//nbcol,trial%nbcol])\n",
    "        plot_raster_one_trial(data,shank,cluster,trial,minTime,maxTime,ax=axT)\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    SHANK=1\n",
    "    CLU=17\n",
    "    #print(data.trialNotTracked)\n",
    "    #plot_raster_one_trial(data,SHANK,CLU,trial=4)\n",
    "\n",
    "    plot_raster_trial_by_trial(data,SHANK,CLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def plot_raster_trial_by_trial_new(data,shank,cluster,group=\"not specified\",minTime=0,maxTime=20,paw=False):\n",
    "def plot_raster_trial_by_trial_new(data,group=\"Good\",minTime=0,maxTime=20,paw=False):\n",
    "    '''\n",
    "    -Raster for all trials with median position (firing rate if nbSpike>20000)\n",
    "    -One plot for every trial (plot_raster_one_trial: position + spike time)\n",
    "    Paw=True: plot paw position\n",
    "    A trial time range is [treadmillStart+minTime, treadmillStart+maxTime]\n",
    "    times are aligned on treadmillStart\n",
    "    '''\n",
    "    #nbcol=3 #nbcol=2 will result in Value Error (plot too big) \n",
    "    #nbLines=int(np.ceil(data.nTrial*1.0/nbcol))\n",
    "    #gs=gridspec.GridSpec(nbLines+1,nbcol,hspace=0.5)\n",
    "\n",
    "    #plt.figure(figsize=(15,nbLines*(15.0/nbcol)))\n",
    "    #ax=plt.subplot(gs[0,0:2])\n",
    "    #if len(data.spikeTime[shank][cluster])<20000:\n",
    "        #plot_raster(data,shank,cluster)\n",
    "    #else:\n",
    "        #plot_raster_firing_rate(data,shank,cluster)\n",
    "    #ax.text(1.2,0.5,\"Shank %s, Cluster %s \\n(group %s)\"%(shank,cluster,group),transform=ax.transAxes,fontsize=15)\n",
    "    \n",
    "    rvalue={}\n",
    "    for shank in data.spikeTime:\n",
    "        rvalue[shank]={}\n",
    "        for cluster in data.spikeTime[shank]:\n",
    "            if cluster not in data.clusterGroup[shank][group]:continue\n",
    "            firingRateSession=[]\n",
    "            for trial in data.trials[:-1]:\n",
    "                cluData=data.spikeTime[shank][cluster]\n",
    "                zero=data.treadmillStartTime[trial]\n",
    "                start=zero+minTime\n",
    "                stop=zero+maxTime\n",
    "                trialSpikeTime=cluData[(cluData>start)&(cluData<stop)]-zero\n",
    "                nbSpike=len(trialSpikeTime)\n",
    "                firingRateTrial=nbSpike/(stop-start)\n",
    "                firingRateSession.append(firingRateTrial)\n",
    "\n",
    "            percentile20 = np.percentile(firingRateSession, 20)\n",
    "            percentile80 = np.percentile(firingRateSession, 80)\n",
    "            median = np.percentile(firingRateSession, 50)\n",
    "            r=(median-percentile20)/(percentile80-median)\n",
    "            rvalue[shank][cluster]=r\n",
    "\n",
    "    #return percentile20,percentile80,median,r\n",
    "    return rvalue\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    #SHANK=1\n",
    "    #CLU=130\n",
    "    #percentile20,percentile80,median,r = plot_raster_trial_by_trial_new(data,SHANK,CLU)\n",
    "    #print(shank,clu,\"r\",rvalues)\n",
    "    rvalue=plot_raster_trial_by_trial_new(data,group=\"Good\")\n",
    "    \n",
    "    for shank in rvalue:\n",
    "        for cluster in rvalue[shank]:\n",
    "            print('shank:',shank,',','clu:',cluster,',',rvalue[shank][cluster])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raster align on the detected end\n",
    "For some trials, detected end is None (not detected). Those trials are not plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_firing_rate_alignEnd(data,shank,cluster,binSize,minTime=-10,maxTime=10):\n",
    "    timeBin=np.arange(minTime,maxTime+binSize-maxTime%binSize,binSize)\n",
    "    firingRate={}\n",
    "    spikeTime=data.spikeTime[shank][cluster]\n",
    "    for trial in data.trials:\n",
    "        end=data.timeEndTrial[trial]\n",
    "        if isNone(end):\n",
    "            continue\n",
    "        zero=data.treadmillStartTime[trial]+end\n",
    "        start=zero+minTime\n",
    "        stop=zero+maxTime\n",
    "        trialSpikeTime=spikeTime[(spikeTime>=start)&(spikeTime<=stop)]\n",
    "        alignedTime=trialSpikeTime-zero\n",
    "        hist,bins=np.histogram(alignedTime,timeBin)\n",
    "        firingRate[trial]=hist/float(binSize)\n",
    "    center=(timeBin[:-1]+timeBin[1:])/2\n",
    "    return firingRate,center,timeBin\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "def plot_raster_firing_rate_alignEnd(data,shank,cluster,binSize=0.25,minTime=-10,maxTime=10,legend=False,ax=None):\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "        \n",
    "    firingRate,center,timeBin=compute_firing_rate_alignEnd(data,shank,cluster,binSize,minTime,maxTime)\n",
    "    res=np.asarray(list(firingRate.values()))\n",
    "\n",
    "    realTrials=[trial+1 for trial in data.trials if not isNone(data.timeEndTrial[trial])]\n",
    "    \n",
    "    y= [t+0.5 for t in range(1,len(realTrials)+2)]\n",
    "    resColor=ax.pcolormesh(timeBin,y,res,cmap=\"Greys\")\n",
    "\n",
    "    box = ax.get_position()\n",
    "    axColor = plt.axes([box.x0*1.02 + box.width * 1.02, box.y0, 0.01, box.height])\n",
    "    plt.colorbar(resColor, cax=axColor, label=\"firing rate\")\n",
    "\n",
    "    yAxis=[y+0.5 for y in range(0,len(realTrials))]\n",
    "    entrance=[data.entranceTime[trial-1]-data.timeEndTrial[trial-1] for trial in realTrials]\n",
    "    ax.plot(entrance,yAxis,\"x\",color=\"red\",label=\"Entrance times\",linewidth=2)\n",
    "\n",
    "    ax2=ax.twinx()\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.plot(data.timeAlignEnd,data.medianPositionAlignEnd,'g-',linewidth=2,label=\"Median position\");\n",
    "    \n",
    "    #set correct ticks and limits\n",
    "    ax.set_xlim([timeBin[0],timeBin[-1]])\n",
    "    ax.set_yticks(yAxis)\n",
    "    for i,label in enumerate(ax.get_yticklabels()):\n",
    "        label.set_visible(not i%(len(yAxis)//10))\n",
    "        \n",
    "    ax.set_yticklabels([str(t) for t in realTrials])\n",
    "    ax.set_ylim(0,len(realTrials))\n",
    "    ax.set_xlabel(\"Time relative to detected end\")\n",
    "    ax.set_ylabel(\"Trial Number\")\n",
    "    ax.set_title(\"Cluster %s aligned end, firing rate, binSize=%s s\"%(cluster,data.binSize))\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "def plot_mean_firing_rate_alignEnd(data,shank,cluster,binSize=0.25,minTime=-10,maxTime=10,sigma=1,ax=None):\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "    \n",
    "    firingRate,center,timeBin=compute_firing_rate_alignEnd(data,shank,cluster,binSize,minTime,maxTime)\n",
    "    spikeCount=np.mean(list(firingRate.values()),axis=0)\n",
    "    \n",
    "    import scipy.ndimage as scImage\n",
    "    smoothSpikeCount=scImage.filters.gaussian_filter1d(spikeCount, sigma) \n",
    "    \n",
    "    ax.plot(center,smoothSpikeCount);\n",
    "    ax.set_xlabel(\"Time relative to detected end\")\n",
    "    ax.set_ylabel(\"Mean firing rate\")\n",
    "    ax.set_title(\"Cluster %s aligned End, firing rate + gaussian (sigma=%s)\"%(cluster,sigma))   \n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    SHANK=1\n",
    "    CLU=17\n",
    "\n",
    "    plt.figure(figsize=(8,15))\n",
    "    plt.subplot(311)\n",
    "    plot_raster_firing_rate(data,SHANK,CLU)\n",
    "\n",
    "    plt.subplot(312)\n",
    "    plot_raster_firing_rate_alignEnd(data,SHANK,CLU)\n",
    "\n",
    "    plt.subplot(313)\n",
    "    plot_mean_firing_rate_alignEnd(data,SHANK,CLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Autocorrelogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phy.stats\n",
    "\n",
    "def plot_autocorrelogram(data, shank, cluster, bin_ms=1,half_width_ms=25,ax=None):\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "    \n",
    "    bin_ms=np.clip(bin_ms,.1,1e3) #bin size in ms, rounded\n",
    "    binsize=int(data.spikeSamplingRate*bin_ms*0.001) #bin size in time samples\n",
    "    \n",
    "    half_width_ms=np.clip(half_width_ms,.1,1e3) #ms, rounded\n",
    "    winsize_bins= 2*int(half_width_ms/bin_ms) +1 #number of bins in window\n",
    "\n",
    "    sample=data.spikeSample[shank][cluster]\n",
    "    clu=np.ones_like(sample,dtype=\"int64\")\n",
    "    \n",
    "    pairwiseCorr=phy.stats.pairwise_correlograms(sample,clu,binsize,winsize_bins)\n",
    "\n",
    "    autoCorr=pairwiseCorr[0,0,:]\n",
    "    \n",
    "    halfWinsize=winsize_bins//2\n",
    "    xaxis=np.arange(-halfWinsize-0.5, halfWinsize+1.5)\n",
    "    xaxis=xaxis*binsize/data.spikeSamplingRate*1000 #ms\n",
    "    \n",
    "    ax.bar(xaxis[:-1],autoCorr,width=bin_ms,color=\"blue\",edgecolor=\"blue\");\n",
    "    ax.set_title(\"Cluster %s, Autocorrelogram\"%cluster);\n",
    "    ax.set_xlim([xaxis[0],xaxis[-1]]);\n",
    "    ax.set_xlabel(\"time (ms), binsize=%s ms\"%bin_ms)\n",
    "    ax.set_ylabel(\"spike count\")\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    shank=1\n",
    "    clusterID = 17\n",
    "\n",
    "    #bin_ms: bin size in ms\n",
    "    bin_ms=1\n",
    "    #half_width_ms: half width of the x axis (time), in ms\n",
    "    half_width_ms=30 #1000\n",
    "\n",
    "    plt.figure(figsize=(15,5))    \n",
    "    plt.subplot(121)\n",
    "    plot_autocorrelogram(data,shank,clusterID,bin_ms,30)\n",
    "    plt.subplot(122)\n",
    "    plot_autocorrelogram(data,shank,clusterID,bin_ms,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelogram for trial/intertrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import phy.stats\n",
    "\n",
    "def plot_autocorrelogram_trial(data,shank,cluster,bin_ms=1,half_width_ms=25,minTime=-5,maxTime=20,inTrial=True,ax=None):\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "    \n",
    "    bin_ms=np.clip(bin_ms,.1,1e3) #bin size in ms, rounded\n",
    "    binsize=int(data.spikeSamplingRate*bin_ms*0.001) #bin size in time samples\n",
    "    \n",
    "    half_width_ms=np.clip(half_width_ms,.1,1e3) #ms, rounded\n",
    "    winsize_bins= 2*int(half_width_ms/bin_ms) +1 #number of bins in window\n",
    "\n",
    "    sample=data.spikeSample[shank][cluster]\n",
    "    spikeTime=data.spikeTime[shank][cluster]\n",
    "    \n",
    "    isInTrial=np.full_like(sample,False)\n",
    "    #select only spike during trials\n",
    "    for trial in data.trials:\n",
    "        start=data.treadmillStartTime[trial]\n",
    "        stop=data.cameraStartTime[trial]+data.stopFrame[trial]/data.cameraSamplingRate\n",
    "        isInTrial=np.logical_or(isInTrial,(spikeTime>start)&(spikeTime<stop))\n",
    "    \n",
    "    if inTrial:\n",
    "        newSample=sample[isInTrial]\n",
    "        title=\"trial\"\n",
    "    else:\n",
    "        newSample=sample[np.invert(isInTrial)]\n",
    "        title=\"intertrial\"\n",
    "    clu=np.ones_like(newSample,dtype=\"int64\")\n",
    "\n",
    "    pairwiseCorr=phy.stats.pairwise_correlograms(newSample,clu,binsize,winsize_bins)\n",
    "\n",
    "    autoCorr=pairwiseCorr[0,0,:]\n",
    "    \n",
    "    halfWinsize=winsize_bins//2\n",
    "    xaxis=np.arange(-halfWinsize-0.5, halfWinsize+1.5)\n",
    "    xaxis=xaxis*binsize/data.spikeSamplingRate*1000 #ms\n",
    "    \n",
    "    ax.bar(xaxis[:-1],autoCorr,width=bin_ms,color=\"blue\",edgecolor=\"blue\");\n",
    "    ax.set_title(\"Cluster %s, Autocorrelogram during %s\"%(cluster,title));\n",
    "    ax.set_xlim([xaxis[0],xaxis[-1]]);\n",
    "    ax.set_xlabel(\"time (ms), binsize=%s ms\"%bin_ms)\n",
    "    ax.set_ylabel(\"spike count\")\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    plt.figure(figsize=(15,10))    \n",
    "    plt.subplot(221)\n",
    "    plot_autocorrelogram_trial(data,shank,clusterID,bin_ms,30)\n",
    "    plt.subplot(222)\n",
    "    plot_autocorrelogram_trial(data,shank,clusterID,bin_ms,1000)\n",
    "    plt.subplot(223)\n",
    "    plot_autocorrelogram_trial(data,shank,clusterID,bin_ms,30,inTrial=False)\n",
    "    plt.subplot(224)\n",
    "    plot_autocorrelogram_trial(data,shank,clusterID,bin_ms,1000,inTrial=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waveform for teresa's data (.kwx)\n",
    "  - Load .kwx with h5py and .kwik with phy  \n",
    "  - Choose randomly 150 spikes from a cluster\n",
    "  - Do not plot spike if mask=0\n",
    "  \n",
    "  in kwik/kwx format, spikeIndex are the index in the kwx file\n",
    "  \n",
    "  spikeSample are the index in dat file (once it's reshaped as `nSample*nChannel`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from phy.session import Session\n",
    "\n",
    "def read_dat_waveform(data, shank, cluster, subSample = 150, extract = 16):\n",
    "    #memory map to dat file\n",
    "    dtype = np.int16\n",
    "    size = os.stat(data.fullPath + '.dat').st_size\n",
    "    row_size = data.nChannels * np.dtype(dtype).itemsize\n",
    "    if size % row_size != 0:\n",
    "        raise ValueError((\"Shape error: the file {f} has S={s} bytes, \"\n",
    "                          \"but there are C={c} channels. C should be a divisor of S.\"\n",
    "                          \"\").format(f=filename, s=size, c=self.nchannels))\n",
    "    nsamples = size // row_size\n",
    "    shape = (nsamples, data.nChannels)\n",
    "    datFile = np.memmap(data.fullPath + '.dat', dtype = dtype, mode = 'r', offset = 0, shape = shape)\n",
    "    #indexes of spikes for this cluster\n",
    "    spikeID = data.spikeSample[shank][cluster]\n",
    "    nSpike = len(spikeID)\n",
    "    if nSpike > subSample:\n",
    "        spikeID = np.random.choice(spikeID, subSample, replace = False)\n",
    "        nSpike = subSample\n",
    "    #get waveform for each index\n",
    "    waveform = np.zeros(shape=(nSpike, extract * 2, len(data.channelGroupList[shank])), dtype=dtype )\n",
    "    for index, spike in enumerate(spikeID):\n",
    "        waveform[index, :, :] = datFile[spike-extract : spike+extract, data.channelGroupList[shank]]\n",
    "    return waveform\n",
    "\n",
    "def read_kwx_waveform(data, shank, clusterID, sample = 150):\n",
    "    \"\"\"\n",
    "    kwx array = [ spikes indexes, n data points, n channels]\n",
    "    \"\"\"\n",
    "    if not os.path.exists(data.fullPath+\".kwx\"):\n",
    "        return\n",
    "    with h5py.File(data.fullPath+\".kwx\",\"r\") as kwx:  \n",
    "        waveform = kwx.get('channel_groups/%s/waveforms_raw' % shank)[()]\n",
    "    print(waveform.shape)\n",
    "    #index of spikes where cluster==X\n",
    "    spikeID=data.spikeIndex[shank][clusterID]\n",
    "    print(max(spikeID))\n",
    "    if len(spikeID) > sample:\n",
    "        spikeID = np.random.choice(spikeID, sample, replace = False)\n",
    "    return waveform[spikeID, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    animal=\"Rat034\"\n",
    "    experiment=\"Rat034_2015_02_10_12_49\" \n",
    "    #experiment=\"Rat034_2015_06_15_10_03\" \n",
    "    data=Data(root,animal,experiment,param,redoPreprocess=True)\n",
    "    for shank in data.channelGroupList:\n",
    "            print(\"shank %s:\"%shank)\n",
    "            print(data.clusterGroup[shank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean waveform from .kwx\n",
    "def plot_mean_waveform(data, shank, clusterID, noPlot = False, sample = 150, kwx = True):\n",
    "    \n",
    "    if kwx:\n",
    "        waveform = read_kwx_waveform(data, shank, clusterID, sample)\n",
    "    else:\n",
    "        waveform = read_dat_waveform(data, shank, clusterID, sample)\n",
    "    \n",
    "    minMax = 0\n",
    "    meanWaveform = []\n",
    "    ch = 0\n",
    "    for channel in range(waveform.shape[2]):\n",
    "        meanChannel = np.mean(waveform[:, :, channel], axis = 0)\n",
    "        minMaxChannel = np.max(meanChannel) - np.min(meanChannel)\n",
    "        if minMaxChannel > minMax:\n",
    "            minMax = minMaxChannel\n",
    "            meanWaveform = meanChannel\n",
    "            ch = channel\n",
    "    if not noPlot:\n",
    "        plt.plot(meanWaveform)\n",
    "        plt.title(\"Mean waveform - Shank %s Cluster %s channel %s\" %(shank, clusterID, ch))\n",
    "    return meanWaveform\n",
    "        \n",
    "#Loading waveform from .kwx\n",
    "def plot_waveforms(data, shank, clusterID, group=\"not specified\", sample = 150, kwx = True):\n",
    "    \n",
    "    if kwx:\n",
    "        waveform = read_kwx_waveform(data, shank, clusterID, sample)\n",
    "    else:\n",
    "        waveform = read_dat_waveform(data, shank, clusterID, sample)\n",
    "    \n",
    "    place = [[0, 1], [1, 0], [2, 1], [3, 0], [4, 1], [5, 0], [6, 1], [7, 0]]           \n",
    "    plt.figure(figsize = (3*2, 6))\n",
    "    plt.suptitle(\"Cluster %s\" % clusterID, fontsize = 14)\n",
    "    gs = gridspec.GridSpec(8, 3, hspace = -0.3, wspace = 0)    \n",
    "    for channel in range(waveform.shape[2]):\n",
    "        channelWaveform = waveform[:, :, channel] \n",
    "        x = place[channel][0]\n",
    "        y = place[channel][1]\n",
    "        ax = plt.subplot(gs[x,y])\n",
    "        for spike in channelWaveform:\n",
    "            ax.plot(spike, color = \"blue\");\n",
    "        ax.set_title(\"%s\" % channel)\n",
    "        ax.set_axis_off() \n",
    "    return\n",
    "\n",
    "#old name of the function\n",
    "plot_waveforms_teresa = plot_waveforms\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    shank = 1\n",
    "    clu = 84\n",
    "    plot_waveforms(data, shank, clu, sample=10,kwx=False)\n",
    "    plt.figure()\n",
    "    plot_mean_waveform(data, shank, clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General plot on each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster_correlogram(data,shank,cluster,group=\"not specify\"):\n",
    "    \n",
    "    cluSpikeTime=data.spikeTime[shank][cluster]\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(222)\n",
    "\n",
    "    if len(cluSpikeTime)>20000:\n",
    "        plot_raster_firing_rate(data,shank,cluster)\n",
    "    else:\n",
    "        plot_raster(data,shank,cluster)\n",
    "        \n",
    "    plt.subplot(224)\n",
    "    plot_mean_firing_rate(data,shank,cluster)\n",
    "    plt.subplot(221)\n",
    "    plot_autocorrelogram(data,shank,cluster,1,30)\n",
    "    plt.subplot(223)\n",
    "    plot_autocorrelogram(data,shank,cluster,1,1000)\n",
    "    \n",
    "    exp=data.experiment\n",
    "    plt.suptitle(\"%s, Shank %s, Cluster %s (group:%s), %s spikes\"%(exp,shank,cluster,group,len(cluSpikeTime)),fontsize=16)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "if \"__file__\" not in dir():\n",
    "    shank=1\n",
    "    cluster=84\n",
    "    plot_raster_correlogram(data,shank,cluster,\"Good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
